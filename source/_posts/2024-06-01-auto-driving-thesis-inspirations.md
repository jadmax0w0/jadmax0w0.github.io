---
title: 自动驾驶关键场景预测项目笔记
date: 2023-12-01 17:32:03
tags:
  - ai
  - auto-driving
---

# 基本概念

## 视觉运行设计域 / 场景表征

- **运行设计域 ODD** (Operational Design Domain)

  SAE J3016 将 ODD 定义为“特定驾驶自动化系统或其功能专门设计的运行条件，包括但不限于环境、地理和时间限制，和/或某些交通或道路特征的存在或缺失。”

  简单来说，ODD就是要定义好在哪些工况下是能够自动驾驶的，脱离了这些工况，自动驾驶就不能保证工作。任何一台自动驾驶车辆，都必须有一定限定的工况。而这个工况可以很宽泛，也可以很精准，并决定了自动驾驶车辆能胜任什么样的场景。比如，一台车的自动驾驶系统只能在高速上使用，它可以自动保持车道、自动超车、自动跟车、自动让行、自动通过ETC、自动上下匝道等，但到了城市里就无法完全自动驾驶。同时，要确保自动驾驶测试和验证是完整的，至少需要确保ODD所有方面已经通过确保系统安全运行，或通过确保系统能够识别超出ODD 的范围。

  在工信部发布的《GBT 汽车驾驶自动化分级》推荐性国家标准中，<u>**ODD是设计时确定的驾驶自动化功能的本车状态和外部环境**</u>。

<!-- 隐藏这一部分

## 深度学习中的分类评估指标

- 精确率

  模型预测对的正样本数占预测得到的所有正样本数的比例：
  $$
  \text{Precision} = \frac{TP}{TP + FP}
  $$

- 召回率

  模型预测正确的正样本数占数据集中所有正样本数的比例：
  $$
  \text{Recall} = \frac{TP}{TP + FN}
  $$

- F1-score

  精确率和召回率的调和平均数：
  $$
    F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
  $$

- 准确率

  模型预测正确的样本数占数据集中所有样本的比例：

  $$
  \text{Accuracy} = \frac{TP + TN}{TP + FP + TN + FN}
  $$

-->

# 场景表征 & 图像编码

> P.S. 图像编码部分并非本人负责，这里只总结一下相关的思路

首先，如果我们已经有了标注信息足够全面的数据集，那么无需再对场景数据进一步编码，只需要套用标注的信息表征场景即可。

但这样的数据集有两个问题：

1. 需要的人力资源大。面对现实世界纷繁复杂的交通状况，根本没有精力去为大量交通数据标注信息；
2. 不同领域标注的重点信息乃至标注的信息格式也不同。这导致无法使用多个数据集训练同一个模型；或者训练出来的模型泛化性不高。

所以，要考虑在缺少标注乃至没有标注的情况下，应该如何提取图像的特征，进而形成涵盖所有场景特征的离散特征空间。

<!--

## 图像编码：卷积神经网络 CNN 及全连接层

- CNN 的组成：卷积层、池化层、全连接层

- ❓ 卷积层的作用？
  它使用卷积核（也称为过滤器）来提取输入数据中的特征，例如图像中的边缘、纹理等。卷积操作可以减少参数数量，进而提高网络的计算效率和泛化能力。

- ❓ 池化层的作用？
  池化层用于降低卷积层输出的空间分辨率，同时保留关键信息。常见的池化操作包括最大池化和平均池化。

- ❓全连接层的作用？
  全连接层位于 CNN 的顶部，通常用于分类任务。

- 全连接层：本质就是普通的线性层。与前一层的每一个神经元、后一层的每一个神经元都有连接。$y=W\cdot x$

  在实际使用中，全连接层可由卷积操作实现：对前层是全连接的全连接层~~可以转化为卷积核为 1x1 的卷积~~ (前一层是全连接层，说明前一层的结果本身就是一个 $1\times v$ 的向量。此时全连接层：) 只相当于再加一个线性层：$\mathbb{R}^{1\times v} \times \mathbb{R}^{v \times w} = \mathbb{R}^{1\times w}$)；而前层是卷积层的全连接层可以转化为卷积核为 $hwc$ 的全局卷积，$h, w, c$ 分别为前层卷积结果的高、宽和通道数 (也就是前一层卷积层结果张量的总的元素数)。

- 示例：
  ![](/images/auto-driving-thesis-reading/cnn_egs.png)

-->

## (半监督) 图像编码：VGG 网络

可以采用“将图像编码”的思路，提取图像的特征，并将其压缩到更小维度的 latent space 中。

用于编码图像 (压缩图像 / 提取图像特征) 的 NN 依旧需要人工标记的场景数据集训练。

- VGG-16 (项目中采用的网络结构)

  ![](/images/auto-driving-thesis-reading/vgg-structures.png)

  > ✨ 项目中只是采用了 VGG-16 网络的卷积池化层，并没有采用最后的三步全连接以及一步 softmax 层，取而代之的是一个平均池化层：
  >
  > ```
  > 224 * 224 * 3  -> [conv3-64]  * 2 -> [maxpool] ->
  > 112 * 112 * 64 -> [conv3-128] * 2 -> [maxpool] ->
  > 56 * 56 * 128  -> [conv3-256] * 3 -> [maxpool] ->
  > 28 * 28 * 256  -> [conv3-512] * 3 -> [maxpool] ->
  > 14 * 14 * 512  -> [conv3-512] * 3 -> [maxpool] ->
  > 7 * 7 * 512    -> [avgpool]       ->
  > 1 * 1 * 512
  > ```
  >
  > 为什么这么做呢？
  >
  > 因为我们只需要图像在 latent space 中编码过的信息，并不需要执行某种分类操作，也就不需要额外的几个全连接层统合图像的特征，更不需要 softmax 层生成归一化概率。
  >
  > 最终采用 average pool 降维而不是 max pool，也是为了尽可能多地保留图片特征。
  >
  > *P.S. 尚未尝试将 average pool 更改为 `kernel=7, channel=512` 的卷积层效果如何。*
  >
  > *P.P.S 注意到最终每一张图片 (每一个场景数据点) 都对应着深度为 512 的向量。而 Apolloscape 的原始交通场景数据集中有 5773 个样本，说明最终形成的特征空间 (编码后的场景空间) 足有 5773 \* 1 \* 512 之大。这已经堪称维度灾难，必须要采用某些方法降维处理。*

## 图像自编码：AE & VAE

图像自编码技术是无监督生成模型的基础，被普遍使用于降维学习、特征学习以及图像生成等应用，主要包括自编码器（AE）和变分编码器（VAE）。

此二种编码器的主要思路均为：原始图像 → 编码器 → latent space representation → 解码器 → 生成的与原始图像相近的图像。优化目标大致为：使得生成图像与原始图像最接近。

注意到图像自编码过程会在 latent space 中表示原始图像，那么我们便可以利用该空间作为场景图像的编码，也就是作为场景表征。

> 能够使用 latent space 的另外一个原因还在于，既然解码器能够根据该 latent space representation 来 (eventually) 生成和原始图像相似乃至相同的新图像，说明该 latent space rep 已经有了足够多原始图像的信息。而且 latent space 往往都是降维表示的，所以自然而然便产生了“使用图像自编码过程中间的 latent space rep 作为我们所需要的图像编码 / 场景表征”的想法。

## 图像自编码：DRIT 网络

> 参考：[DRIT：Diverse image-to-image translation via disentangled representations 论文阅读-CSDN博客](https://blog.csdn.net/john_bh/article/details/106604470)

DRIT 网络将图像表示为两个 latent space representation：代表图像画面内容的 content space，以及代表图像画面属性 (*风格 / 感觉 / 样式…*) 的 attribute space；而且，这两个 latent space 之间是无耦合 (disentangled) 的。

应用到本项目中来，我们或许可以将“是否有雾霾”作为每个场景的 attribute，场景画面自然作为 content。这样不仅可以利用 DRIT 的两种编码器 (attribute encoder & content encoder) 的编码结果作为场景表征，更可以利用 DRIT 生成雾霾 / 去雾图像作为新的场景数据。

> 上述两种无监督的图像自编码方式依旧有“特征空间维度过高”的问题。

## 将场景的特征空间降维：主成分分析法线性降维 (无监督方法)

<!-- 数学基础

### 特征值和特征向量

$$
\mathbf{A} \vec{v} = a \cdot \vec{v}
$$

一个向量左乘一个矩阵之后，和单纯用一个标量 scale 这个向量得到的结果向量一致。这样的 $a, \vec v$ 便是矩阵 $\mathbf{A}$​ 的一对特征值和特征向量。

> ❓ 那么对于张量呢？

### 协方差矩阵



### PCA 概念

[机器学习笔记（九）——数据降维：主成分分析法（PCA）_主成分分析法数据样本-CSDN博客](https://blog.csdn.net/weixin_43312354/article/details/105653308)

[PCA降维原理及其代码实现（附加 sklearn PCA用法参数详解）_头歌用python完成pca(data,k)函数,实现降维功能-CSDN博客](https://blog.csdn.net/kobeyu652453/article/details/107058229)

-->

使用 PCA，在较大程度保留原特征空间的各个特征的情况下，将其降维。

由于PCA只需要通过特征值分解来实现数据降维，因此是一种无监督的降维方法。当协方差矩阵维数较高时，也可以通过奇异值分解（SVD）的方法获取PCA的解，可以明显地降低计算复杂度。

# “在场景那离散、巨大的特征空间中搜索”

## 用于在特征空间中搜索的 NN 结构：长短时记忆网络 LSTM

<!--

> 参考：
>
> 1. [长短时记忆网络(LSTM)(超详细 |附训练代码)_lstm代码-CSDN博客](https://blog.csdn.net/qq_73462282/article/details/132073333)
> 2. [深度学习基础（六）：LSTM模型及原理介绍-CSDN博客](https://blog.csdn.net/lyc_yongcai/article/details/73201446)

-->

111

<!--

> ❓ 为什么使用 RNN 在特征空间中搜索？
>
> 从现实世界出发，在对道路交通场景的朴素认知上来讲，“这一刻车多人多、道路情况复杂”必定意味着“下一刻车多人仍多、道路情况依旧复杂”。也就是说，最差感知场景 (待搜索的关键场景) 之间是有一定的时序特征、能够形成一系列序列的。由此出发，放到 NN 的角度，如果在 $t$ 时刻的输入既有当前场景信息 $\vec x_t$，又有来自 $t-1$ 时刻的输出信息 $\vec h_{t-1}$ ($\vec h_{t-1}$ 隐含场景信息；或者说它就是在 latent space 下的 $x_{t-1}$​)，那么无疑会取得更好的训练效果 (*一句话：the input pattern of RNN is consistent with 现实世界的情况*)。
>
> 那么接下来的工作，便是选用一种稳定、高效的 RNN 模型了。此处选用 LSTM。

LSTM 基本单元可以实现时序信号的输入以及相应的时序信息的输出，而 $h_t$ 输出中蕴含了大量时序和语义特征，可以通过 softmax 层映射为输出向量，我们则是将其映射到场景参数空间上。

> ❓ 设 $h_t$ 映射到场景参数空间上的结果为 $m_t$，那么是否将 $m_t$ 作为 $x_{t+1}$​ 再次输入 LSTM 呢？另外，具体是如何映射的？

> ❓ 如何训练这个 LSTM 呢 (如何优化 LSTM 的**参数**)？以及咋就想到去优化 LSTM 的**超参数**了？

## 如何优化应用于上述 NN 的超参数 (NAS 问题)：强化学习

> ❓ 为什么可以使用强化学习的方式来优化上述 LSTM 模型？
>
> 结合上面提到过的“对道路交通场景的朴素认知”，不难意识到，当 NN 搜索到一个在当前参数配置下可能的最差感知场景后，可以“顺水推舟”搜索到 (大致) 符合时间顺序的一系列场景。不难意识到该搜索过程便是一个 MDP，而产生的一系列场景 (搜索结果) 便是在该 MDP 上 explore 的过程；这些搜索结果形成了一个 trajectory。
>
> 有了一个隐含的 MDP，又有了在该 MDP 上采样得到的 trajectory，要优化该 MDP *(LSTM 模型预测场景的过程)* 的 policy *(该 policy 受 LSTM 预测场景时所采用的超参数影响，可以记作 $a = \pi_\theta (s) = \pi (s, \theta)$)*，自然便应用强化学习。

采用优化方法：策略梯度下降法。

> ❓ 为什么没有使用 Q-Learning？
>
> 因为 Q-Learning 是针对离散 MDP 的优化方法，要求状态空间和动作集合都是离散的 (某年的期末题就出的这个…)。而此处的 LSTM 决策过程 (优化目标：其超参数) 明显是在连续空间上进行的，无法应用 Q-Learning。

-->

# 场景样本检索 & 重排序

场景样本检索本质上就是图像检索问题，不同于单一的检索任务，本工作需要实现**场景级的图像集合检索算法**以支持搜索和预测框架的迭代，目标是<u>找到具有相同场景的最差性能样本集</u>。依赖于图像检索算法实现上层场景实例匹配任务，本文的场景样本检索更加关注于<u>在保证 top-k 精度的同时，样本间的场景关联性要足够的强</u>，对于对应场景表征具有较好的代表能力。

> ❓ 场景样本检索得到的 k 近邻场景 (场景实例) 和场景空间采样得到的场景特征是如何联系起来的？
>
> 使用场景空间采样得到的场景特征作为 probe 输入检索算法得到 k 近邻场景？还是使用场景样本检索得到的一些最差感知场景优化 LSTM 的参数？(应该不是后者……)

搜索过程大致为：LSTM 模型在场景的离散特征空间中搜索得到一系列可能的最差感知场景特征 → 将这些特征作为 query 输入场景样本检索算法，每个特征将对应检索得到的一组相同场景的样本 → 将所有样本交给场景匹配器，检测是否匹配最差感知场景，若匹配……

> 为了解决理想假设对搜 索方法泛用性和应用价值的限制，本文通过多种场景表征构建搜索空间，提出在搜索 框架中融入重排序技术来进一步提高匹配样例集的内部场景一致性，以改进场景样本 的匹配性能，并增加了实例集判别器来判断场景表征和对应场景实例集是否有效命中， 避免场景空间数据稀疏导致的强制匹配出现。

## $K-reciprocal$​ 重排序 (混合重排序)

<!--

## 半监督学习 伪标注方法

适用于小样本学习：伪标签技术

伪标签的定义来自于半监督学习，半监督学习的核心思想是通过借助无标签的数据来提升有监督过程中的模型性能。

粗略来讲，伪标签技术就是利用在已标注数据所训练的模型在未标注的数据上进行预测，根据预测结果对样本进行筛选，再次输入模型中进行训练的一个过程。

-->
